- Paso 1: Crear docker-compose.yaml
# Tener instalado VS Studio Code
# Tener instalado Docker Desktop

version: '3'

services:
  # Zookeeper 1 (Leader)
  zookeeper-1:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper-1
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVERS: "zookeeper-1:2888:3888;zookeeper-2:2888:3888;zookeeper-3:2888:3888"
    volumes:
      - zookeeper-data-1:/var/lib/zookeeper
    networks:
      - kafka-net

  # Zookeeper 2 (Follower)
  zookeeper-2:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper-2
    ports:
      - "2182:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVERS: "zookeeper-1:2888:3888;zookeeper-2:2888:3888;zookeeper-3:2888:3888"
    volumes:
      - zookeeper-data-2:/var/lib/zookeeper
    networks:
      - kafka-net

  # Zookeeper 3 (Follower)
  zookeeper-3:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper-3
    ports:
      - "2183:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 3
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVERS: "zookeeper-1:2888:3888;zookeeper-2:2888:3888;zookeeper-3:2888:3888"
    volumes:
      - zookeeper-data-3:/var/lib/zookeeper
    networks:
      - kafka-net

  # Kafka 1
  kafka-1:
    image: confluentinc/cp-kafka:latest
    container_name: kafka-1
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT"
      KAFKA_LISTENERS: "INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL: "PLAINTEXT"
      KAFKA_ADVERTISED_LISTENERS: "INSIDE://kafka-1:9092,OUTSIDE://kafka-1:9093"
      KAFKA_LISTENER_INTERNAL: "INSIDE"
      KAFKA_LISTENER_EXTERNAL: "OUTSIDE"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INSIDE"  # A√±adir esta l√≠nea para definir el listener inter-broker
    networks:
      - kafka-net

  # Kafka 2
  kafka-2:
    image: confluentinc/cp-kafka:latest
    container_name: kafka-2
    ports:
      - "9093:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT"
      KAFKA_LISTENERS: "INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL: "PLAINTEXT"
      KAFKA_ADVERTISED_LISTENERS: "INSIDE://kafka-2:9092,OUTSIDE://kafka-2:9093"
      KAFKA_LISTENER_INTERNAL: "INSIDE"
      KAFKA_LISTENER_EXTERNAL: "OUTSIDE"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INSIDE"  # A√±adir esta l√≠nea para definir el listener inter-broker
    networks:
      - kafka-net

  # Kafka 3
  kafka-3:
    image: confluentinc/cp-kafka:latest
    container_name: kafka-3
    ports:
      - "9094:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT"
      KAFKA_LISTENERS: "INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL: "PLAINTEXT"
      KAFKA_ADVERTISED_LISTENERS: "INSIDE://kafka-3:9092,OUTSIDE://kafka-3:9093"
      KAFKA_LISTENER_INTERNAL: "INSIDE"
      KAFKA_LISTENER_EXTERNAL: "OUTSIDE"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INSIDE"  # A√±adir esta l√≠nea para definir el listener inter-broker
    networks:
      - kafka-net

  # Kafka UI
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: "docker-cluster"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka-1:9092,kafka-2:9093,kafka-3:9094"
    networks:
      - kafka-net

networks:
  kafka-net:
    driver: bridge

volumes:
  zookeeper-data-1:
  zookeeper-data-2:
  zookeeper-data-3:
 

- Paso 2: Limpiar Contenedores y Vol√∫menes
docker-compose down -v
docker system prune -a -f
# Esto elimina todos los contenedores y vol√∫menes asociados, asegurando que la nueva configuraci√≥n se aplique correctamente.

- Paso 3: Reiniciar el Cluster
docker-compose up -d
# Esto descargar√° e iniciar√° los contenedores de Zookeeper, Kafka y Kafka UI.
docker ps -a
# Si ves zookeeper-1, zookeeper-2, zookeeper-3, kafka-1, kafka-2, kafka-3 y kafka-ui en la lista, todo est√° funcionando.

- Paso 4: Ver Logs de Zookeeper y kafka
docker logs zookeeper-1
docker logs kafka-1
# Esto permite ver los logs de kafka y zookeeper para revisar errores

- Paso 5: Acceder a la Interfaz Gr√°fica (Kafka UI)
http://localhost:8080
# Desde aqu√≠ puedes administrar los topics de Kafka de forma visual.

######################### PROBAR KAFKA DESDE FUERA DEL CONTENEDOR ###############################################

- Paso 6: Probar Kafka desde la Terminal de VS Code

docker exec -it kafka-1 kafka-topics --create --topic mi-topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 3
# Crear un topic con 3 particiones y replicaci√≥n en los 3 nodos

docker exec -it kafka-1 kafka-topics --list --bootstrap-server localhost:9092
# Listar los topics creados

docker exec -it kafka-1 kafka-console-producer --broker-list localhost:9092 --topic mi-topic
# Enviar un mensaje al topic (Productor)

docker exec -it kafka-2 kafka-console-consumer --bootstrap-server localhost:9093 --topic mi-topic --from-beginning
# Leer mensajes del topic (Consumidor)

- Paso 7: Apagar el Cluster
docker-compose down
# Cuando termines de usar Kafka, puedes detener los contenedores

######################### PROBAR KAFKA DESDE ADENTRO DEL CONTEDOR ################################################

1 Con√©ctate a un contenedor de Kafka
# Para ejecutar comandos de Kafka, primero ingresa a uno de los brokers de Kafka. Por ejemplo, accede a kafka-1:
docker exec -it kafka-1 bash
# Dentro del contenedor, ve a la carpeta donde est√°n los scripts de Kafka:
cd /usr/bin

2 Crea un t√≥pico en Kafka
# Ejecuta el siguiente comando para crear un nuevo t√≥pico llamado "test-topic":
kafka-topics --create --topic test-topic --bootstrap-server kafka-1:9092 --partitions 3 --replication-factor 3
Esto hace que: ‚úÖ Kafka cree 3 particiones del t√≥pico.
‚úÖ Cada partici√≥n tenga copias en los 3 brokers.
‚úÖ Un broker act√∫e como l√≠der para cada partici√≥n.
# Para verificar que el t√≥pico est√° replicado, usa:
kafka-topics --describe --topic test-topic --bootstrap-server kafka-1:9092
Ì†ΩÌ¥π Leader: Es el broker que maneja las escrituras en la partici√≥n.
Ì†ΩÌ¥π Replicas: Son los brokers que tienen copias del dato.
Ì†ΩÌ¥π Isr (In-Sync Replicas): Brokers que est√°n sincronizados con el l√≠der.
# Para verificar que el t√≥pico fue creado correctamente, usa:
kafka-topics --list --bootstrap-server kafka-1:9092
# Debe aparecer en la lista:
test-topic

3 Enviar mensajes con un Producer
# Para enviar mensajes al t√≥pico test-topic, ejecuta:
kafka-console-producer --topic test-topic --bootstrap-server kafka-1:9092
# Se abrir√° una l√≠nea donde puedes escribir mensajes. Por ejemplo, escribe:
Hola Kafka!
Mensaje de prueba
Presiona Enter despu√©s de cada mensaje.

4 Leer mensajes con un Consumer
# Desde otra terminal en VS Code, con√©ctate nuevamente al contenedor:
docker exec -it kafka-1 bash
# Ejecuta el siguiente comando para leer los mensajes enviados:
kafka-console-consumer --topic test-topic --bootstrap-server kafka-1:9092 --from-beginning
# Deber√≠as ver los mensajes enviados desde el Producer.

######################### HACER PRUEBAS DE FALLOS DESDE KAFKA #######################################

Prueba de fallos
# Para probar la tolerancia a fallos, apaga un broker y verifica que los mensajes siguen disponibles:
docker stop kafka-1
# Luego, intenta consumir mensajes desde otro broker:
docker exec -it kafka-2 bash
kafka-console-consumer --topic test-topic --bootstrap-server kafka-2:9092 --from-beginning
kafka-console-consumer --topic test-topic --bootstrap-server kafka-3:9092 --from-beginning
# Si todo est√° bien, Kafka reasignar√° el l√≠der a otro broker y seguir√° funcionando. 


########################## EXPLICACI√ìN COMO FUNCIONA REPLICACI√ìN EN KAFKA #############################

Ì†ΩÌª† C√≥mo funciona la replicaci√≥n en Kafka
Cada t√≥pico en Kafka tiene m√∫ltiples particiones.

Cada mensaje que env√≠es se almacena en una partici√≥n espec√≠fica.
Cada partici√≥n tiene un l√≠der y seguidores en otros brokers.

Un broker act√∫a como l√≠der de la partici√≥n.
Los otros brokers contienen copias (r√©plicas) de la partici√≥n.
El l√≠der maneja las escrituras y los seguidores sincronizan los datos.

Cuando produces un mensaje, Kafka lo escribe en la partici√≥n l√≠der.
Los otros brokers replican los mensajes desde el l√≠der.
























